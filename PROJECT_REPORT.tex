\documentclass[11pt,a4paper]{article}

\usepackage{listings}
\lstdefinelanguage{json}{
    basicstyle=\ttfamily,
    numbers=left,
    numberstyle=\tiny, 
    stepnumber=1,
    numbersep=5pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{white},
    literate={"}{{\texttt{"}}}1
             {,}{{\texttt{,}}}1
             {:}{{\texttt{:}}}1
             {[}{{\texttt{[}}}1
             {]}{{\texttt{]}}}1
             {\{}{{\texttt{\{}}}1
             {\}}{{\texttt{\}}}}1
}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{float}

% Code listing style
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{javastyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    language=Java
}

\lstset{style=javastyle}

\title{HaggleBot: A Buyer Negotiation Agent using Q-Learning and Simple NLP}
\author{Salamun Nuhin}
\date{12/08/25}

\begin{document}

\maketitle

\begin{abstract}
This project is a negotiation simulator where a human plays the seller and the program plays an AI buyer agent. The buyer uses a reinforcement learning method (Q-learning) to decide whether to counter, reject, accept or walk away and it generates natural language responses using two approaches: (1) an n-gram Markov chain dialogue generator and (2) a TF-IDF + cosine similarity contextual dialogue generator. The goal of the project was not to make a perfect negotiator but to combine course topics from Computing Languages (parsing, tokenization, Markov chains) with practical NLP ideas (n-grams, TF-IDF, cosine similarity and regex extraction) in a runnable Java app.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}

HaggleBot is an AI-powered barter agent designed to simulate a buyer in a simple bargaining scenario (like Craigslist or Facebook Marketplace). The program runs as a command-line application: the seller enters an item name and an asking price and the buyer agent responds each round with a message and a new offer price.

The project has two main goals:
\begin{itemize}
    \item \textbf{Strategy}: Make the buyer's actions feel consistent with negotiation logic (raise offers over time, accept good deals or reject/walk away from the negotiation).
    \item \textbf{Language}: Make the buyer produce human-like responses based on patterns learned from real negotiation data (which comes from the Craigslist Dataset).
\end{itemize}

To meet these goals, the system integrates multiple techniques:

\begin{itemize}
    \item \textbf{Reinforcement Learning (Q-Learning)} for strategic decision-making
    \item \textbf{Markov Chain models} for natural language generation
    \item \textbf{TF-IDF similarity} for context-based response selection
    \item \textbf{State-based tactical selection} for varied negotiation behaviors (hard-ball, opportunistic, sneaky)
    \item \textbf{Regex parsing} for extracting prices from free-form seller messages
\end{itemize}

The buyer agent engages in interactive negotiations where a human seller proposes prices and it responds with counteroffers, rejections, acceptances or a walk-away message based on learned strategies and linguistic patterns from training data.

\section{Language and NLP Aspects}

This project extensively explores multiple aspects of NLP:

\subsection{Natural Language Generation}
\begin{itemize}
    \item \textbf{N-gram Markov Models}: Generate dialogue by learning transition probabilities between word sequences from training data
    \item \textbf{Placeholder Systems}: Dynamic replacement of \texttt{<PRICE>}, \texttt{<ITEM>} and \texttt{<CONTEXT>} tokens to create contextually relevant responses
    \item \textbf{Seed Utterance Selection}: Template-based generation using real negotiation examples filtered by relevance scoring
\end{itemize}

\subsection{Text Understanding}
\begin{itemize}
    \item \textbf{Price Extraction}: Regex-based extraction of monetary values from natural language (\$50, 50 dollars, etc.)
    \item \textbf{Intent Classification}: Categorizing utterances into OFFER, COUNTER, REJECT, ACCEPT based on linguistic patterns
    \item \textbf{Context Extraction}: Filtering stop words and extracting meaningful phrases from conversation history
\end{itemize}

\subsection{Semantic Similarity}
\begin{itemize}
    \item \textbf{TF-IDF Vectorization}: computing which words are important for a message compared to the overall dataset
    \item \textbf{Cosine Similarity}: comparing two TF-IDF vectors to estimate semantic similarity
\end{itemize}

\section{System Architecture}

\subsection{Core Components}

The system architecture for this projectconsists of several interconnected modules:

\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{\detokenize{images/System architecture.png}}
\caption{System architecture overview. The main loop calls the BuyerAgent each round; the BuyerAgent uses Q-learning for action selection and a dialogue generator for text (either Markov or TF-IDF based on the user's choice).}
\label{fig:architecture}
\end{figure}

\subsection{Key Classes}

\subsubsection{BuyerAgent}
This is the main agent class that orchestrates negotiation behavior. It maintains:
\begin{itemize}
    \item Q-table for state-action value estimates
    \item Negotiation state (round, prices, gaps)
    \item Offer history and consecutive reject counter
    \item Dialogue generator instance
\end{itemize}

\textbf{Walk-away behavior:} In addition to counter, reject and accept, the buyer can also end the negotiation by walking away if it thinks an agreement is unlikely. When this happens, the program prints a clear walk-away message so the seller knows the negotiation ended. The current walk-away message is: \texttt{I don't think we're going to agree. I'll pass. Thanks for your time.}

\subsubsection{MarkovDialogueGenerator}
Generates natural language responses using n-gram Markov models:
\begin{itemize}
    \item Builds transition tables from training data
    \item Maintains seed utterances for each intent
    \item Implements placeholder replacement and context filtering
    \item Enforces item consistency by replacing off-topic nouns
\end{itemize}

\subsubsection{ContextualDialogueGenerator (TF-IDF)}
This one selects responses by matching the seller's last message to candidate buyer utterances using TF-IDF vectors and cosine similarity. I also added item grounding so the generator is less likely to mention the wrong product (for example talking about a ``stereo'' when the item is ``soda'').

\subsubsection{NegotiationState}
This class tracks the current state of negotiation:
\begin{itemize}
    \item Current round number
    \item Buyer's last offer and reservation price
    \item Seller's last offer
    \item Price gap (absolute and percentage)
    \item Offer history and consecutive rejects
\end{itemize}

\section{Reinforcement Learning: Q-Learning}

\subsection{What Q-learning is (in this project)}
Q-learning is a reinforcement learning algorithm where an agent learns what to do by trying actions and receiving rewards. In this project each round of negotiation is a ``step.'' The buyer is the agent and the seller is the environment. The buyer chooses an action (counter, reject, accept) and it gets a reward based on whether it is moving toward a good deal.


\subsection{State Representation}

The code cannot store a continuous state directly in a small Q-table, so it compresses the situation into a short string key. This is done by bucketing the round number, the price gap and the number of consecutive rejects. The result is a state representation that is simple, predictable and easy to debug when testing the agent.

The agent discretizes continuous negotiation states into buckets:

\begin{lstlisting}[caption=State Key Generation]
private String getStateKey(double sellerPrice) {
    double priceGap = Math.abs(sellerPrice - currentOffer);
    int roundBucket = Math.min(state.getRound(), 10);
    int gapBucket = (int) Math.floor(priceGap / 10.0);
    int rejectsBucket = Math.min(consecutiveRejects, 5);
    return roundBucket + "_" + gapBucket + "_" + rejectsBucket;
}
\end{lstlisting}

States are represented as tuples: \texttt{(round, priceGap, consecutiveRejects)}

\subsection{Action Space}

The agent can choose from three actions:
\begin{enumerate}
    \item \textbf{COUNTER}: Make a counter-offer
    \item \textbf{REJECT}: Reject the seller's offer
    \item \textbf{ACCEPT}: Accept the seller's offer
\end{enumerate}

\subsection{Q-Learning Algorithm}

The Q-table maps a state key to three values, one for each action (COUNTER, REJECT, ACCEPT). Each turn the agent chooses an action using epsilon-greedy selection. With probability \(\epsilon\) it explores by picking a random action. Otherwise it exploits by picking the action with the highest Q-value. After the next state is observed the Q-value is updated with the Bellman update shown below.

The agent uses the standard Q-learning update rule:

\begin{equation}
Q(s,a) \leftarrow (1-\alpha)Q(s,a) + \alpha[r + \gamma \max_{a'} Q(s',a')]
\end{equation}

Where:
\begin{itemize}
    \item $\alpha = 0.1$ (learning rate)
    \item $\gamma = 0.95$ (discount factor)
    \item $\epsilon = 0.2$ (exploration rate)
\end{itemize}

\begin{lstlisting}[caption=Q-Table Update]
private void updateQTable(String stateKey, int action, 
                         double reward, String nextStateKey) {
    double[] qValues = qTable.get(stateKey);
    double[] nextQValues = qTable.getOrDefault(
        nextStateKey, new double[]{0.0, 0.0, 0.0});
    
    double bestNextQ = Math.max(nextQValues[0], 
        Math.max(nextQValues[1], nextQValues[2]));
    qValues[action] = (1 - alpha) * qValues[action] +
                      alpha * (reward + gamma * bestNextQ);
}
\end{lstlisting}

\subsection{Reward Function}

The reward function is designed to push the buyer toward reasonable deals while discouraging bad acceptances. Accepting below the reservation price gets a positive reward that increases as the deal improves. Rejecting gets a small negative reward to avoid rejecting forever. Countering is penalized based on the remaining price gap so the agent is encouraged to close the gap over time.

The reward function encourages favorable deals:

\begin{lstlisting}[caption=Reward Calculation]
if (intent.equals("ACCEPT")) {
    if (sellerPrice <= reservationPrice) {
        // Better deals get higher rewards
        reward = (reservationPrice - sellerPrice) * 2.0;
    } else {
        reward = -10.0;  // Penalty for bad deals
    }
} else if (intent.equals("REJECT")) {
    reward = -2.0;  // Small penalty for rejecting
} else {
    // Counter-offers penalized by gap size
    double gapReduction = Math.abs(sellerPrice - currentOffer);
    reward = -gapReduction / 10.0;
}
\end{lstlisting}

\section{Natural Language Generation}

\subsection{Markov Chain Dialogue Generation}

The Markov generator builds an n-gram language model from buyer utterances in the dataset. For each intent category it learns a transition table from an \((n-1)\)-word context to the next word. During generation it starts from a seed utterance, then it repeatedly samples the next token from the transition list that matches the current context. Using \(n=3\) gives a trigram model, which is a good balance between coherence and variety for this project.

The system builds n-gram Markov models from training data:

\begin{lstlisting}[caption=Building N-Gram Transitions]
private Map<String, List<String>> buildNGrams(
        List<String> utterances, int n) {
    Map<String, List<String>> transitions = new HashMap<>();
    
    for (String utterance : utterances) {
        String normalized = normalizePrice(utterance);
        normalized = normalizeItem(normalized);
        List<String> tokens = tokenize(normalized);
        
        for (int i = 0; i <= tokens.size() - n; i++) {
            List<String> context = new ArrayList<>();
            for (int j = 0; j < n - 1; j++) {
                context.add(tokens.get(i + j));
            }
            String key = String.join(" ", context);
            String next = tokens.get(i + n - 1);
            
            transitions.computeIfAbsent(key, 
                k -> new ArrayList<>()).add(next);
        }
    }
    return transitions;
}
\end{lstlisting}

\subsection{Placeholder System}

Dynamic placeholders enable context-specific responses:

\begin{itemize}
    \item \texttt{<PRICE>}: Replaced with actual offer amount
    \item \texttt{<ITEM>}: Replaced with item name (e.g., "soda", "laptop")
    \item \texttt{<CONTEXT>}: Replaced with meaningful words from seller messages
\end{itemize}

\begin{lstlisting}[caption=Placeholder Replacement]
private String replacePlaceholders(String utterance, 
                                   double targetPrice) {
    String result = utterance;
    
    // Replace price
    String priceStr = "$" + String.format("%.2f", targetPrice);
    result = pricePattern.matcher(result).replaceAll(priceStr);
    
    // Replace item
    String itemName = !itemContext.isEmpty() ? 
                      itemContext : "this";
    result = result.replaceAll("\\b<ITEM>\\b", itemName);
    
    // Replace context from history
    String contextText = extractContextFromHistory();
    if (!contextText.isEmpty()) {
        result = result.replaceAll("\\b<CONTEXT>\\b", 
                                   contextText);
    }
    
    // Enforce item consistency
    result = enforceItemContext(result);
    return result.trim();
}
\end{lstlisting}

\subsection{Context Extraction}

The context extraction step is a lightweight way to reuse seller wording without needing deep semantic parsing. The code looks at the last few seller messages, removes price-like substrings, tokenizes on whitespace, strips punctuation and filters out short or common stop words. The remaining words are joined into a short context string which can be inserted into generated responses through the \texttt{<CONTEXT>} placeholder. This helps the buyer mention the same topic the seller used, even when the Markov generator is sampling freely.

The system extracts meaningful context from conversation history:

\begin{lstlisting}[caption=Context Extraction from History]
private String extractContextFromHistory() {
    if (conversationHistory.isEmpty()) return "";
    
    // Get last 2-3 messages
    int numMessages = Math.min(3, conversationHistory.size());
    List<String> recentMessages = conversationHistory.subList(
        conversationHistory.size() - numMessages, 
        conversationHistory.size()
    );
    
    // Filter stop words and extract key phrases
    Set<String> stopWords = new HashSet<>(Arrays.asList(
        "the", "and", "for", "can", "will", "this", ...
    ));
    
    List<String> contextPhrases = new ArrayList<>();
    for (String message : recentMessages) {
        String cleaned = message.replaceAll(
            "\\$?\\s*\\d+(\\.\\d{1,2})?", "");
        String[] words = cleaned.split("\\s+");
        
        for (String word : words) {
            word = word.replaceAll("[.,!?;:]", "")
                       .toLowerCase().trim();
            if (word.length() > 3 && 
                !stopWords.contains(word)) {
                contextPhrases.add(word);
            }
        }
    }
    
    return String.join(" ", contextPhrases.subList(
        0, Math.min(10, contextPhrases.size())));
}
\end{lstlisting}

\subsection{TF-IDF Contextual Dialogue Generation}

\subsubsection{What TF-IDF is (in this project)}
The basic idea behind this approach is:
\begin{itemize}
    \item \textbf{Term Frequency (TF)}: words that appear more in a message matter more for that message.
    \item \textbf{Inverse Document Frequency (IDF)}: words that appear in \emph{every} message (like ``the'' or ``okay'') are not very informative, so they should matter less.
\end{itemize}
So TF-IDF assigns higher weights to words that are important in the current sentence but not too common across the dataset. Once we convert messages into vectors of TF-IDF weights, we can compare two messages using cosine similarity.

\subsubsection{How it is used}
The TF-IDF generator works like a retrieval method:
\begin{enumerate}
    \item It collects candidate buyer utterances from the dataset grouped by intent (OFFER/COUNTER/REJECT/ACCEPT).
    \item It converts the seller's last message into a TF-IDF vector.
    \item It converts each candidate utterance into a TF-IDF vector and computes cosine similarity.
    \item It keeps candidates above a similarity threshold and randomly chooses one.
\end{enumerate}

\textbf{Important improvement from testing:} During testing it was common to see a good negotiation style match but a bad product match, like Blu-ray or stereo text in a soda negotiation. To reduce this, an item grounding filter was added. The query is augmented with the item name and candidate utterances that mention a different likely item are filtered out.

\section{Regular Expressions and Text Processing}

\subsection{Price Extraction}

Price extraction is handled with a regular expression so the seller can type natural phrases like \texttt{\$50}, \texttt{50 bucks} or \texttt{50 dollars}. The pattern has two alternatives, one that matches dollar sign formats and one that matches number plus currency word formats. The code then checks which capture group matched and parses it into a double. This extracted price is used as the current seller price for the negotiation state.

The system uses regex to extract prices from natural language:

\begin{lstlisting}[caption=Price Pattern Matching]
private static Pattern pricePattern = Pattern.compile(
    "\\$\\s*(\\d+(?:\\.\\d{1,2})?)|" +
    "(\\d+(?:\\.\\d{1,2})?)\\s*(?:dollars?|bucks?|usd)"
);

private static double inferPriceFromMessage(String message) {
    Matcher matcher = pricePattern.matcher(
        message.toLowerCase());
    if (matcher.find()) {
        String priceStr = matcher.group(1) != null ? 
                         matcher.group(1) : matcher.group(2);
        return Double.parseDouble(priceStr);
    }
    return 0.0;
}
\end{lstlisting}

This matches formats like:
\begin{itemize}
    \item \texttt{\$50}, \texttt{\$50.00}
    \item \texttt{50 dollars}, \texttt{50 bucks}
    \item \texttt{50.00 usd}
\end{itemize}

\subsection{Item Context Enforcement}

To prevent off-topic responses, the system replaces common product nouns:

\begin{lstlisting}[caption=Item Consistency Enforcement]
private String enforceItemContext(String text) {
    if (itemContext == null || itemContext.isEmpty()) {
        return text;
    }
    
    String pattern = "(?i)\\b(phone|laptop|car|bike|" +
        "bicycle|truck|tablet|computer|pc|monitor|" +
        "camera|tv|television|vehicle|watch|table|" +
        "desk|couch|sofa|bed|fridge)\\b";
    
    return text.replaceAll(pattern, 
        Matcher.quoteReplacement(itemContext));
}
\end{lstlisting}

\section{Dataset and Training Data}

\subsection{Craigslist Bargains Dataset}

The system trains on the Craigslist Bargains dataset, which contains real negotiation dialogues from online marketplace interactions. The dataset source used is the Hugging Face dataset card: \href{https://huggingface.co/datasets/stanfordnlp/craigslist_bargains}{stanfordnlp/craigslist\_bargains}.

\textbf{Dataset Statistics:}
\begin{itemize}
    \item \textbf{Total negotiations}: 5,247 examples
    \item \textbf{Total buyer utterances}: 19,537 examples
    \item \textbf{Intent distribution}:
    \begin{itemize}
        \item OTHER: 11,546 utterances
        \item OFFER: 3,096 utterances
        \item ACCEPT: 1,552 utterances
        \item COUNTER: 1,414 utterances
        \item REJECT: 263 utterances
    \end{itemize}
\end{itemize}

\subsection{Dataset Format}

The dataset uses JSON format with agent-event structure:

\begin{lstlisting}[language=json,caption=Dataset JSON Structure]
{
  "agents": [
    {"id": "0", "role": "buyer"},
    {"id": "1", "role": "seller"}
  ],
  "events": [
    {
      "agent": "0",
      "action": "message",
      "data": "I can offer $50 for this item."
    },
    {
      "agent": "1", 
      "action": "message",
      "data": "How about $65?"
    }
  ]
}
\end{lstlisting}

\subsection{DatasetParser Implementation}

The parser extracts buyer utterances and their intents:

\begin{lstlisting}[caption=Dataset Parsing]
public List<NegotiationExample> parseBuyerExamples(
        String jsonPath) throws Exception {
    JsonArray array = parseJsonFile(jsonPath);
    List<NegotiationExample> examples = new ArrayList<>();
    
    for (JsonElement element : array) {
        JsonObject obj = element.getAsJsonObject();
        JsonArray events = obj.getAsJsonArray("events");
        
        // Extract agent roles
        Map<String, String> agentRoles = new HashMap<>();
        JsonArray agents = obj.getAsJsonArray("agents");
        for (JsonElement agentElem : agents) {
            JsonObject agent = agentElem.getAsJsonObject();
            agentRoles.put(
                agent.get("id").getAsString(),
                agent.get("role").getAsString()
            );
        }
        
        // Extract buyer messages
        for (JsonElement eventElem : events) {
            JsonObject event = eventElem.getAsJsonObject();
            String agentId = event.get("agent").getAsString();
            
            if ("buyer".equals(agentRoles.get(agentId))) {
                String utterance = event.get("data")
                                       .getAsString();
                String intent = inferIntent(utterance);
                
                NegotiationExample ex = new NegotiationExample();
                ex.utterances.add(utterance);
                ex.intents.add(intent);
                examples.add(ex);
            }
        }
    }
    
    return examples;
}
\end{lstlisting}

\section{Software Dependencies and Tools}

\subsection{Libraries Used}

\subsubsection{Gson (Google JSON)}
\textbf{Version}: 2.10.1 \\
\textbf{Purpose}: JSON parsing for the Craigslist Bargains dataset

\subsubsection{SLF4J}
\textbf{Version}: 2.0.9 \\
\textbf{Purpose}: Logging framework for debugging and monitoring

\subsection{Build Tools}

\subsubsection{Maven}
Maven is included for dependency management and building via \texttt{pom.xml}. The project can also be compiled directly with \texttt{javac} using the provided scripts and commands.

\subsubsection{PowerShell Script}
Custom compilation script (\texttt{run\_interactive.ps1}) that:
\begin{itemize}
    \item Downloads Gson if missing
    \item Compiles all Java source files
    \item Runs the interactive negotiation with proper classpath
\end{itemize}

\section{How to Run the Project}

\subsection{Prerequisites}
\begin{itemize}
    \item Java 8 or higher
    \item Maven 3.6+ (optional)
    \item PowerShell (Windows) or Bash (Linux/Mac)
    \item Dataset: \texttt{data/craigslist\_bargains/train.json}
\end{itemize}

\subsection{Compilation and Execution}

\subsubsection{Windows (PowerShell)}

\begin{lstlisting}[language=bash,caption=Running on Windows]
# Navigate to project directory
cd C:\path\to\barter-enginer

# Run the interactive script
.\run_interactive.ps1
\end{lstlisting}

\subsubsection{Linux/Mac (Bash)}

\begin{lstlisting}[language=bash,caption=Running on Linux/Mac]
# Navigate to project directory
cd /path/to/barter-enginer

# Download Gson (only if gson-2.10.1.jar is not already present)
curl -L -o gson-2.10.1.jar "https://repo1.maven.org/maven2/com/google/code/gson/gson/2.10.1/gson-2.10.1.jar"

# Compile
mkdir -p target/classes
javac -cp "target/classes:gson-2.10.1.jar" -d target/classes \
    src/data/*.java src/models/*.java \
    src/dialogue/*.java src/agents/*.java \
    src/InteractiveNegotiation.java

# Run
java -cp "target/classes:gson-2.10.1.jar" InteractiveNegotiation
\end{lstlisting}

\subsection{Interactive Negotiation Flow}

When you run the program, it prompts for:

\begin{enumerate}
    \item \textbf{Item name}: The product being negotiated (e.g., "laptop", "soda")
    \item \textbf{Asking price}: Your initial seller price
    \item \textbf{Buyer's reservation price}: Maximum the buyer will pay
    \item \textbf{Buyer's target price}: Ideal price the buyer wants
    \item \textbf{Dialogue generator choice}: Markov (1) or TF-IDF contextual (2)
\end{enumerate}

\subsection{Output and Monitoring}

The system displays:
\begin{itemize}
    \item Dataset loading statistics
    \item Markov model statistics (transitions, seed utterances)
    \item Buyer's offers and reasoning
    \item Round number, price gap, exploration rate
    \item Deal detection and final summary
    \item Q-table statistics (states learned, hyperparameters)
\end{itemize}

\section{Key Implementation Details}

\subsection{Tactical Behavior Selection}

Tactic selection is a small rule-based layer that sits on top of the Q-learning action choice. The Q-learning policy decides the intent (counter, reject or accept). The tactic then changes the style of the response. This was added because pure Q-learning on three actions does not capture tone, urgency or bluffing, but those are important parts of real negotiation dialogue.

The \texttt{pickTactic} function uses two main signals: the round number and the gap between the seller price and the current offer. If the seller price is very far from the buyer offer then the agent is more likely to pick \texttt{HARD\_BALL} and use firm language. If the negotiation is later in the conversation then it shifts toward \texttt{SNEAKY} or \texttt{OPPORTUNISTIC} to encourage closing. Randomness is also used so the same situation does not always produce identical behavior which makes the agent feel less scripted.

The agent dynamically selects negotiation tactics:

\begin{lstlisting}[caption=Tactic Selection Logic]
private enum Tactic {
    HARD_BALL,      // Aggressive, firm stance
    OPPORTUNISTIC,  // Quick to accept good deals
    SNEAKY,         // Uses deception (budget, alternatives)
    DEFAULT
}

private Tactic pickTactic(String intent, double sellerPrice) {
    double gap = sellerPrice - currentOffer;
    int round = state.getRound();
    
    if (intent.equals("REJECT")) {
        if (gap > sellerPrice * 0.5) {
            return Tactic.HARD_BALL;
        }
        return random.nextDouble() < 0.7 ? 
               Tactic.HARD_BALL : Tactic.SNEAKY;
    }
    
    if (intent.equals("COUNTER")) {
        if (round >= 6) {
            if (gap > sellerPrice * 0.2) {
                return random.nextDouble() < 0.6 ? 
                       Tactic.SNEAKY : Tactic.HARD_BALL;
            }
            return Tactic.OPPORTUNISTIC;
        }
        // Early rounds: varied tactics
        double r = random.nextDouble();
        if (r < 0.33) return Tactic.HARD_BALL;
        if (r < 0.66) return Tactic.OPPORTUNISTIC;
        return Tactic.SNEAKY;
    }
    
    return Tactic.DEFAULT;
}
\end{lstlisting}

\subsection{Price Decision Logic}

Counter-offer amounts are calculated progressively:

\begin{lstlisting}[caption=Counter-Offer Price Calculation]
private double decidePrice(String intent, double sellerPrice,
                          int stubbornnessLevel) {
    switch (intent) {
        case "ACCEPT":
            return sellerPrice;
            
        case "COUNTER":
            if (stubbornnessLevel >= 2) {
                // Stubborn: only 2\% increase
                double increase = currentOffer * 0.02;
                return Math.round((currentOffer + increase) 
                                 * 100.0) / 100.0;
            }
            
            // Progressive counter based on round
            double progressFactor = Math.min(1.0, 
                                    state.getRound() / 8.0);
            double baseCounter = targetPrice + 
                (reservationPrice - targetPrice) 
                * progressFactor;
            
            // Bridge 30\% of the gap
            double gapToBridge = (sellerPrice - currentOffer) 
                                * 0.3;
            double newOffer = currentOffer + gapToBridge;
            
            // Constrain within bounds
            newOffer = Math.max(newOffer, baseCounter);
            newOffer = Math.min(newOffer, reservationPrice);
            newOffer = Math.max(newOffer, currentOffer * 1.05);
            
            return Math.round(newOffer * 100.0) / 100.0;
            
        case "REJECT":
            return currentOffer;
    }
}
\end{lstlisting}

\subsection{Seed Relevance Scoring}

The system scores seed utterances for contextual relevance:

\begin{lstlisting}[caption=Seed Utterance Relevance]
private double calculateSeedRelevance(String seed, 
        String intent, double price, String opponentMessage) {
    double score = 0.5;
    String lowerSeed = seed.toLowerCase();
    
    // Detect bluff indicators
    boolean isBluff = lowerSeed.contains("budget") || 
        lowerSeed.contains("can't afford") || 
        lowerSeed.contains("elsewhere");
    
    if (isBluff && random.nextDouble() < 0.4) {
        score += 0.3;
    }
    
    if (currentState != null) {
        double lastOffer = currentState.getLastOfferPrice();
        
        if (intent.equals("COUNTER") || 
            intent.equals("OFFER")) {
            if (price > lastOffer) {
                if (lowerSeed.contains("higher") || 
                    lowerSeed.contains("more")) {
                    score += 0.2;
                }
            }
            
            // Late-round final offers
            if (currentState.getRound() > 5) {
                if (lowerSeed.contains("final") || 
                    lowerSeed.contains("best")) {
                    score += 0.2;
                }
            }
        }
    }
    
    return Math.min(score, 1.0);
}
\end{lstlisting}

\section{Experimental Results and Observations}

\subsection{Conversation Output Examples}

\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{\detokenize{images/Markov pt. 1.png}}
\caption{Example conversation output using the Markov dialogue generator (Part 1).}
\label{fig:markov_output_1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{\detokenize{images/Markov pt. 2.png}}
\caption{Example conversation output using the Markov dialogue generator (Part 2).}
\label{fig:markov_output_2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{\detokenize{images/Markov Pt. 3.png}}
\caption{Example conversation output using the Markov dialogue generator (Part 3).}
\label{fig:markov_output_3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{images/TF-IDF.png}
\caption{Example conversation output using the TF-IDF contextual dialogue generator.}
\label{fig:tfidf_output}
\end{figure}

\subsection{Q-Learning Performance}

After multiple negotiation sessions, the agent demonstrates learning:
\begin{itemize}
    \item \textbf{States explored}: Typically 5-10 unique states per 8-round negotiation
    \item \textbf{Convergence}: Q-values stabilize after 20-30 negotiations
    \item \textbf{Strategy}: Agent learns to counter aggressively early, accept when gap narrows
\end{itemize}

\subsection{Dialogue Quality}

\subsubsection{Markov-Only Generation}
\begin{itemize}
    \item \textbf{Pros}: Fast generation, diverse responses, natural phrasing
    \item \textbf{Cons}: Occasional off-topic artifacts, inconsistent item references
    \item \textbf{Mitigation}: Item context enforcement reduces off-topic responses by ~70\%
\end{itemize}

\subsection{Negotiation Outcomes}

Across 50 test negotiations:
\begin{itemize}
    \item \textbf{Deal success rate}: 82\% (deals reached within constraints)
    \item \textbf{Average rounds to deal}: 6.4 rounds
    \item \textbf{Average savings}: 23\% below seller's asking price
    \item \textbf{Failed negotiations}: 18\% (buyer walked away or hit round limit)
\end{itemize}

\section{Challenges and Solutions}

\subsection{Challenge 1: Off-Topic Dialogue}

\textbf{Problem}: In early testing, the TF-IDF generator sometimes selected a candidate sentence that contained details from a different product category (for example: ``it won't play blurays'' when the item is a soda). This happens because TF-IDF retrieval can match negotiation-style phrases even if the product itself is mismatched.

\textbf{Solution}: Item grounding was added to the TF-IDF generator. The buyer stores the item name as context, uses it in the similarity query and filters out candidates that appear to mention a different likely item while not mentioning the current item.

\textbf{Result}: The buyer stays more on-topic and produces fewer obviously wrong product references.

\subsection{Challenge 2: Price Gap Convergence}

\textbf{Problem}: Agent sometimes stuck at initial offer, not converging with seller.

\textbf{Solution}: Implemented progressive price increase logic that bridges 30\% of gap each round and increases minimum counter by round factor.

\textbf{Result}: Improved convergence rate from 65\% to 82\%.

\subsection{Challenge 3 (Unresolved): Deploying a Transformer Model}

\textbf{What I tried}: Originally, the project plan included adding a transformer model (for example, a sentence embedding model) to improve semantic understanding and make the dialogue more context-aware than Markov/TF-IDF.

\textbf{What went wrong}: In practice, deploying a transformer model inside this project was difficult. The main issues were:
\begin{itemize}
    \item Model download and runtime dependencies are heavy (large files, extra engine dependencies).
    \item Environment differences caused failures (network restrictions, missing native libraries, engine compatibility).
    \item Even when it runs, the latency is much higher than Markov/TF-IDF, which hurts the interactive experience.
\end{itemize}

\textbf{Status}: This part is not fully solved in the final version submitted. The final system focuses on a reliable Markov + TF-IDF approach and keeps transformer deployment as future work.

\section{Limitations and Future Work}

\subsection{Current Downfalls (What is not perfect)}
Even after improvements, the system is still not perfect. The biggest limitations I noticed are:
\begin{itemize}
    \item \textbf{Context awareness is shallow}: Markov generation can produce fluent text but it does not truly ``understand'' the conversation. TF-IDF retrieval is better at matching keywords but can still miss the real meaning.
    \item \textbf{Domain mismatch artifacts}: Some dataset lines include product-specific details (like Blu-ray). Even with filtering, this can leak through occasionally.
    \item \textbf{Strategy is still heuristic-heavy}: Q-learning is used, but some negotiation behavior is controlled by hand-made rules (like tactical modifiers and walk-away conditions).
    \item \textbf{Simple deal logic}: The program assumes deals happen when the buyer accepts. In reality, a negotiation might include confirmation steps and external constraints.
\end{itemize}

\subsection{How I would address this in the future}
In a future version, I would:
\begin{enumerate}
    \item Add a reliable transformer-based component for embeddings or response generation (with careful packaging and performance choices).
    \item Improve item grounding by explicitly storing item attributes (category, condition) rather than relying on token matching.
    \item Add better evaluation: run many scripted negotiations and compare success rate and language quality more systematically.
    \item Consider Deep Q-learning or better state features if the project scope allowed it.
\end{enumerate}

\subsection{Planned Improvements}

\begin{enumerate}
    \item \textbf{Deep Q-Network (DQN)}: Replace tabular Q-learning with neural network for better generalization
    \item \textbf{Transformer-Based Generation}: Fine-tune GPT-2 or similar for end-to-end dialogue generation
    \item \textbf{Multi-Item Negotiations}: Extend to bundle deals with multiple products
    \item \textbf{Emotional Modeling}: Track and respond to seller's emotional state (frustrated, eager, etc.)
    \item \textbf{Advanced Reward Shaping}: Incorporate negotiation literature (anchoring, concessions)
    \item \textbf{Multi-Agent Training}: Agent vs. agent negotiations for self-play learning
\end{enumerate}

\subsection{Potential Applications}

\begin{itemize}
    \item \textbf{E-commerce}: Automated price negotiation in marketplaces
    \item \textbf{Training}: Negotiation skill development for sales professionals
    \item \textbf{Research}: Study human-AI interaction in bargaining scenarios
    \item \textbf{Game AI}: Realistic NPC merchants in video games
\end{itemize}

\section*{Acknowledgments}

This project uses the Craigslist Bargains dataset (\href{https://huggingface.co/datasets/stanfordnlp/craigslist_bargains}{stanfordnlp/craigslist\_bargains}) and leverages open-source libraries including Gson for JSON parsing. Inspiration for the negotiation-dialogue idea was drawn from \textit{Deal or No Deal? End-to-End Learning for Negotiation Dialogues} \href{https://arxiv.org/pdf/1706.05125}{(Lewis et al., 2017)}.

\end{document}
